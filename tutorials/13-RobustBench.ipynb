{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('secml-malware': conda)",
   "metadata": {
    "interpreter": {
     "hash": "920e6f16d919fd37ee1019d40bfa14f341859d5274f6aed429526ec4c95ed979"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Testing attacks against RobustBench models\n",
    "\n",
    "In this tutorial, we will show how to correctly import [RobustBench](https://github.com/RobustBench/robustbench) models inside SecML, and how to craft adversarial evasion attacks against them using SecML.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Warning**\n",
    "\n",
    "Requires installation of the `pytorch` extra dependency.\n",
    "See [extra components](../index.rst#extra-components) for more information.\n",
    "\n",
    "</div>\n",
    "\n",
    "We start by installing the models offered by RobustBench, a repository of pre-trained adversarially robust models, written in PyTorch.\n",
    "All the models are trained on CIFAR-10.\n",
    "To install the library, just open a terminal and execute the following command:\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/RobustBench/robustbench\n",
    "```\n",
    "\n",
    "After the installation, we can import the model we like among the one offered by the library ([click here](https://github.com/RobustBench/robustbench/tree/master/model_info) for the complete list):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from robustbench.utils import load_model\n",
    "model = load_model(model_name='Carmon2019Unlabeled', norm='Linf')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 36,
   "outputs": []
  },
  {
   "source": [
    "This command will create a `models` directory in the current working directory, where it will download the desired model, specified by the `model_name` parameter.\n",
    "Since it is a PyTorch model, we can just load one sample from CIFAR-10 to test it.\n",
    "\n",
    "Again, the dataset will be downloaded inside a `data` directory in our current working directory."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Predicted classes: [3, 8]\n",
      "Real classes: [3, 8]\n"
     ]
    }
   ],
   "source": [
    "from robustbench.data import load_cifar10\n",
    "\n",
    "X, Y = load_cifar10(n_examples=10)\n",
    "y_pred = model(X[:2])\n",
    "print(f\"Predicted classes: {y_pred.argmax(axis=1).tolist()}\")\n",
    "print(f\"Real classes: {Y[:2].tolist()}\")"
   ]
  },
  {
   "source": [
    "# Load RobustBench models inside SecML\n",
    "\n",
    "We can now import the pre-trained robust model inside SecML. Since these models are all coded in PyTorch, we just need to use the PyTorch wrapper of SecML.\n",
    "\n",
    "In order to do this, we need to express the `input_shape` of the data, and feed the classifier with the flatten version of the array (under the hood, the framework will reconstruct the original shape):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted class: 3\n"
     ]
    }
   ],
   "source": [
    "from secml.ml.classifiers.pytorch.c_classifier_pytorch import CClassifierPyTorch\n",
    "\n",
    "secml_model = CClassifierPyTorch(model, input_shape=(3,32,32), pretrained=True)\n",
    "x = X[0].flatten()\n",
    "y_pred = secml_model.predict(x)\n",
    "print(f\"Predicted class: {y_pred[0].item()}\")\n"
   ]
  },
  {
   "source": [
    "# Computing evasion attacks\n",
    "\n",
    "Now that we have imported the model inside SecML, we can compute attacks against it.\n",
    "We will use the iterative Projected Gradient Descent (PGD) attack, with `l2` perturbation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Real class: 3\nPredicted class after the attack: 5\n"
     ]
    }
   ],
   "source": [
    "from secml.adv.attacks.evasion import CAttackEvasionPGD\n",
    "from secml.data import CDataset\n",
    "\n",
    "noise_type = 'l2'   # Type of perturbation 'l1' or 'l2'\n",
    "dmax = 0.5          # Maximum perturbation\n",
    "lb, ub = 0, 1       # Bounds of the attack space. Can be set to `None` for unbounded\n",
    "y_target = None     # None if `error-generic` or a class label for `error-specific`\n",
    "\n",
    "x0, y0 = X[0], Y[0]\n",
    "\n",
    "# Should be chosen depending on the optimization problem\n",
    "solver_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_iter': 100, \n",
    "    'eps': 1e-3\n",
    "}\n",
    "\n",
    "pgd_ls_attack = CAttackEvasionPGD(\n",
    "    classifier=secml_model,\n",
    "\tdouble_init_ds=CDataset(X[0].flatten(), Y[0]),\n",
    "    distance=noise_type, \n",
    "    dmax=dmax, \n",
    "    lb=lb, ub=ub,\n",
    "    solver_params=solver_params,\n",
    "    y_target=y_target)\n",
    "\n",
    "y_pred_pgd, _, _, _ = pgd_ls_attack.run(x0.flatten(), y0)\n",
    "print(f\"Real class: {y0}\")\n",
    "print(f\"Predicted class after the attack: {y_pred_pgd.item()}\")"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}